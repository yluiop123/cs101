# Amdahl法则

Amdahl法则可以用来计算通过并行运行部分计算可以加速多少。
Amdahl法则以Gene Amdahl的名字命名，他在1967年提出了这个法则。
大多数使用并行或并发系统的开发人员即使不知道Amdahl法则，也对潜在的加速有一定的直观感觉。尽管如此，了解Amdahl法则可能仍然有用。

我将首先从数学上解释Amdahl法则，然后使用图表来说明Amdahl法则。

## Amdahl法则定义

可以并行化的程序（或算法）可以分为两部分：
- 无法并行化的部分
- 可以并行化的部分

设想一个从磁盘处理文件的程序。该程序的一小部分可能会扫描目录并在内存中创建文件列表。之后，每个文件被传递给单独的线程进行处理。扫描目录和创建文件列表的部分无法并行化，但处理文件可以。

程序串行（不并行）执行所需的总时间称为T。时间T包括非并行化和并行化部分的时间。非并行化部分称为B。并行化部分称为T - B。以下列表总结了这些定义：
- T = 串行执行的总时间
- B = 非并行化部分的总时间
- T - B = 并行化部分的总时间（当串行执行时，而不是并行）

由此得出：
```
T = B + (T-B)
```

一开始，程序的并行化部分在方程中没有自己的符号可能看起来有点奇怪。然而，由于方程的并行化部分可以使用总时间T和B（非并行化部分）来表示，方程实际上在概念上已经被简化了，这意味着它在这个形式中包含的不同变量更少。

可以通过并行执行来加速的部分是 `T - B`。它可以加速多少取决于你应用了多少线程或CPU来执行它。线程或CPU的数量称为N。因此，并行化部分可以执行的最快速度是：
```
(T - B) / N
```

另一种写法是：
```
(1/N) * (T - B)
```

如果你在Wikipedia上阅读了Amdahl法则，他们会使用这个版本。

根据Amdahl法则，当使用N个线程或CPU执行并行化部分时，程序的总执行时间如下：
```
T(N) = B + (T - B) / N
```

T(N)表示使用N个并行化因子的总执行时间。因此，T可以写成T(1)，意味着使用1个并行化因子的总执行时间。使用T(1)代替T，Amdahl法则看起来像这样：
```
T(N) = B + ( T(1) - B ) / N
```

不过，它的意思还是一样的。

### 计算示例
为了更好地理解Amdahl法则，让我们通过一个计算示例来理解。程序的总执行时间设定为1。程序的非并行化部分是40%，占总时间1的0.4。
因此，并行化部分等于 `1 - 0.4 = 0.6`。

使用并行化因子2（2个线程或CPU执行并行化部分，所以N是2）的程序执行时间将是：
```
T(2) = 0.4 + ( 1 - 0.4 ) / 2
     = 0.4 + 0.6 / 2
     = 0.4 + 0.3
     = 0.7
```

使用并行化因子5而不是2进行相同计算将如下所示：
```
T(5) = 0.4 + ( 1 - 0.4 ) / 5
     = 0.4 + 0.6 / 5
     = 0.4 + 0.12
     = 0.52
```

## Amdahl法则图解
为了更好地理解Amdahl法则，我将尝试说明这个法则是如何推导的。

首先，一个程序可以被分解为非并行化部分B和并行化部分1-B，如下图所示：
![img](https://jenkov.com/images/java-concurrency/amdahls-law-1.png)

顶部带分隔符的线条是总时间T(1)。

这里你看到的是并行化因子为2的执行时间：
![img](https://jenkov.com/images/java-concurrency/amdahls-law-2.png)

这里你看到的是并行化因子为3的执行时间：
![img](https://jenkov.com/images/java-concurrency/amdahls-law-3.png)

## 优化算法
根据Amdahl法则，可以自然地推断出，通过增加硬件，可以更快地执行并行化部分。更多的线程/CPU。然而，非并行化部分只能通过优化代码来加快执行速度。
因此，你可以通过优化非并行化部分来提高程序的速度和并行性。你甚至可以通过将一些工作转移到并行化部分（如果可能的话），来改变算法，使其总体上非并行化部分更小。

### 优化顺序部分
如果你优化了程序的顺序部分，你也可以使用Amdahl法则来计算优化后的程序执行时间。如果非并行化部分B被优化了O倍，那么Amdahl法则看起来像这样：
```
T(O,N) = B / O + (1 - B / O) / N
```

记住，程序的非并行化部分现在需要 `B / O` 时间，所以并行化部分需要 `1 - B / O` 时间。

如果B是0.4，O是2，N是5，那么计算看起来像这样：
```
T(2,5) = 0.4 / 2 + (1 - 0.4 / 2) / 5
       = 0.2 + (1 - 0.4 / 2) / 5
       = 0.2 + (1 - 0.2) / 5
       = 0.2 + 0.8 / 5
       = 0.2 + 0.16
       = 0.36
```

## 执行时间与加速
到目前为止，我们只使用Amdahl法则来计算优化或并行化后程序或算法的执行时间。我们还可以使用Amdahl法则来计算_加速_，即新算法或程序比旧版本快多少。

如果旧版程序或算法的时间是T，那么加速将是
```
Speedup = T / T(O,N)
```

我们通常将T设置为1，只是为了计算执行时间和加速作为旧时间的一部分。然后方程看起来像这样：
```
Speedup = 1 / T(O,N)
```

如果我们用T(O,N)代替Amdahl法则的计算，我们得到以下公式：
```
Speedup = 1 / ( B / O + (1 - B / O) / N )
```

B = 0.4，O = 2，N = 5时，计算变为：
```
Speedup = 1 / ( 0.4 / 2 + (1 - 0.4 / 2) / 5)
        = 1 / ( 0.2 + (1 - 0.4 / 2) / 5)
        = 1 / ( 0.2 + (1 - 0.2) / 5 )
        = 1 / ( 0.2 + 0.8 / 5 )
        = 1 / ( 0.2 + 0.16 )
        = 1 / 0.36
        = 2.77777 ...
```

这意味着，如果你将非并行化（顺序）部分优化了2倍，并并行化了并行化部分的5倍，新优化版本的程序或算法最多可以比旧版本快2.77777倍。

## 衡量，而不仅仅是计算
虽然Amdahl法则可以让你计算出算法并行化的理论加速，但不要过于依赖这样的计算。在实践中，当你优化或并行化一个算法时，可能还会有许多其他因素起作用。

内存的速度、CPU缓存内存、磁盘、网卡等（如果使用磁盘或网络）也可能成为限制因素。如果算法的新版本被并行化，但导致更多的CPU缓存未命中，你可能甚至无法获得使用x N个CPU的预期x N倍加速。如果你最终饱和了内存总线、磁盘或网卡或网络连接，情况也是如此。

我建议使用Amdahl法则来了解在哪里优化，但使用测量来确定优化的实际加速。记住，有时高度序列化的顺序（单CPU）算法可能比并行算法表现更好，仅仅是因为顺序版本没有协调开销（分解工作并再次构建总数），而且单CPU算法可能更好地符合底层硬件的工作方式（CPU流水线、CPU缓存等）。
