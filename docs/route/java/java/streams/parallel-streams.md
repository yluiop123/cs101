# 并行流

## 优化流计算

Stream API 一个非常激动人心的特性是流能够并行处理数据。使用Stream API并行处理数据就像在任何现有流上调用 `parallel()` 方法一样简单。

```java
int parallelSum =
    IntStream.range(0, 10)
             .parallel()
             .sum();

```

运行此代码将得到以下结果。

```
parallelSum = 45
```

实际上，这个和是并行计算的。不过，在这个小例子中，您可能不会注意到任何性能提升。

为什么您想并行计算您的数据？可能为了更快地获得计算结果。并行流会比顺序流更快地给出结果吗？嗯，这个问题的答案并不像听起来那么简单。在某些情况下是的，但在其他情况下，不幸的是，不是的。并行流并不总是比顺序流更快。

记住这一点，您应该小心：选择使用并行流并不是一个轻易做出的决定。在考虑并行之前，您需要问自己几个问题。

首先，问自己，您需要它吗？您的应用程序是否有未满足的性能需求？您确定性能问题来自您考虑并行计算的流处理吗？您如何计划测量性能提升，以确保对这种特定计算并行化提高了应用程序的性能？

并行消耗更多的计算能力。您有额外的CPU或CPU核心可以提供给这个计算吗？您可以在不影响应用程序其余部分的情况下给计算更多的CPU周期吗？

并行消耗线程。您有额外的线程可以提供给您的计算吗？如果您在web服务器上运行的应用程序中工作，那么您的线程被用来提供HTTP请求。您是否愿意用它们做其他事情？

一旦您决定并行，那么您需要确保流计算的性能确实提高了。您应该在尽可能接近生产环境的上下文中测量这种性能提升。

在本教程中，我们涵盖了几个关键要素，这些要素将帮助您评估您可能期望的并行收益，以及一些应该让您警惕并行的要素。但最终，唯一能告诉您是否值得并行的是测试和测量执行时间。

## 并行化实现

并行化是通过递归分解流正在处理的数据来实现的。它建立在Fork/Join框架之上，该框架在JDK 7中添加。

分解包括将流正在处理的数据分成两部分。然后，每个部分由自己的CPU核心处理，该核心可能决定再次递归地将其分解。

在某个时刻，框架将决定给定部分的数据量足够小，可以正常处理。然后，这个数据子集将被处理，并计算出一个部分结果。然后，这个部分结果将与其他在其他CPU核心上计算的部分结果合并。

并行确实有一定的开销。这种开销必须与在几个CPU核心上分布计算的收益相比小。如果不是，那么并行将恶化而不是提高计算的性能。

让我们逐一检查所有这些步骤，并看看什么可以阻止您获得更好的性能提升。

## 理解数据局部性

数据局部性对于数据多快可以被处理有影响，无论是顺序处理还是并行处理。局部性越好，计算速度就越快。

为了使数据可供CPU使用，您的数据必须从计算机的主内存传输到CPU的缓存中。从物理上讲，主内存是计算机的一个特定组件，与您的CPU分开。另一方面，缓存与CPU的核心计算元素共享相同的硅片。它们通过主板和不同的通信总线连接在一起。将数据从主内存传输到CPU的缓存比CPU核心可以从其缓存访问数据的速度慢得多。

当您的CPU需要一些数据时，它首先检查这些数据是否在其缓存中可用。如果是，那么它可以直接使用。如果没有，那么这些数据必须从主内存中获取并复制到缓存中。这种情况称为_cache miss_。缓存未命中代价高昂，因为在这段时间里您的CPU正在等待您的数据。您希望避免这种情况。

数据在主内存和CPU缓存之间传输的方式在避免缓存未命中方面起着重要作用。内存以行组织。通常，一行长64字节，即八个`long`值（这可能因CPU而异）。所有主内存和CPU缓存之间的传输都是按行进行的。所以即使您的CPU只需要一个`int`值，包含这个值的整行也被传输到缓存中。

### 迭代原始类型数组

假设您的代码正在迭代类型为`int[]`的数组。64字节的一行可以容纳16个`int`值。假设访问数组的第一个元素是缓存未命中。然后，CPU将加载包含这个元素的行到其缓存中以开始迭代。因为它加载了一整行，接下来的15个值也可能已经被传输了。访问下一个值将非常快。

在这种情况下，_data locality_非常好：您的数据物理存储在主内存的连续区域。这是可取的，因为将数据从主内存传输到CPU缓存将比顺序处理要快得多。

### 迭代Integer实例数组

现在假设您的代码正在迭代类型为`Integer[]`的数组。您真正拥有的不再是原始类型的数组，而是引用数组。这个数组的每个单元格包含一个引用，指向可能在内存任何位置的`Integer`类型对象。

如果对数组的第一个元素的访问是缓存未命中，那么CPU将不得不将包含这个元素的行加载到其缓存中。它真正加载的是数组的前16个引用，假设这个第一个引用在行的开头。然后它必须加载第一个`Integer`对象，可能在主内存的其他地方，导致另一个缓存未命中。事实上，您的数组中每个`Integer`对象的每次读取可能也会是缓存未命中。

在这种情况下，_data locality_不如前一个例子好：对您的数据的引用物理存储在主内存的连续区域，但您需要进行计算的值不是。这是不可取的，因为将您需要的值从主内存传输到CPU缓存比原始类型数组的情况要慢得多。

### 迭代Integer实例的链表

让我们考察最后一个情况。现在假设您的代码正在迭代类型为`LinkedList<Integer>`的列表。如果对第一个元素的访问是缓存未命中，那么CPU将把链表的第一个节点加载到其缓存中。该节点包含两个引用：第一个是对您需要进行计算的值的引用，第二个是对列表的下一个节点的引用。这种情况比前一个更糟：访问列表的下一个值可能会产生两个缓存未命中。

在这种情况下，_data locality_是可怕的：您的数据和对它们的引用都没有存储在主内存的连续区域。访问您需要的元素将比我们考察的第一个案例慢得多。

### 避免指针追逐

需要跟随引用或指针以到达携带您需要的数据的正确元素称为_pointer chasing_。指针追逐是您希望在应用程序中避免的，并且是许多性能问题的来源。在迭代`int`值数组时不存在指针追逐。当迭代`Integer`实例的链表时，它构成了您的主要性能损失。

## 分割数据源

如果您决定并行处理流，第一步将包括分割您的数据源。为了使分割有效，它应该具有几个属性。

- 分割数据结构应该容易且快速。
- 分割应该是均匀的：您得到的两个子流应该具有相同数量的数据要处理。

### 分割集合实例

`ArrayList`是分割的完美数据结构。您可以轻松地获得中间元素，如果您通过中间分割数组，您确切知道两个子数组将有多少元素。

另一方面，`LinkedList`不是一个好的分割结构。获取中间元素需要逐个遍历列表的一半元素，这是昂贵的，因为指针追逐。一旦到达那里，您可以获得具有正确元素数量的两个子列表。

`HashSet`是建立在桶数组上的，所以分割这个数组就像分割数组列表的内部数组一样。但是数据存储在这个数组中的方式不同。以这种方式分割这个数组，保证两部分有相同数量的元素是更难的。您甚至可能最终得到一个空的子部分。

`TreeSet`基于红黑树实现。它保证所有节点的左右子节点具有相同数量的元素。所以将`TreeSet`的实例分割成两个相等的子树是容易的。不过，您仍然需要追逐指针来到达您的数据。

所有这些结构都在集合框架中使用，您可以获得它们各自携带的元素数量。

这不是您可以创建流的所有结构的情况。

### 分割文本文件的行

对于`Files.lines(path)`模式也是如此，本教程前面已经介绍过。它创建了一个流，该流处理由这个`path`对象表示的文本文件的行。在不分析它的情况下，不可能获得文本文件的行数。

同样适用于我们也介绍过的`Pattern.splitAsStream(line)`模式。它使用提供的模式从`line`的分割中创建流。同样，您无法提前知道在这样的流中将处理多少元素。

### 分割范围或生成流

数字的专业流也为您提供了创建流的模式。

`IntStream.range(0, 10)`流易于分割。实际上，它看起来像一个您可以按中间分割的数字数组。每个部分中的元素数量是可预测的，这是可取的。

另一方面，`Stream.generate()`和`Stream.iterate()`方法不会给您一个易于分割的数据源。实际上，这个源可能是无限的，只是受到您在流中处理它的方式的限制。

让我们比较以下两个模式。

```java
List<Integer> list1 =
    IntStream.range(0, 10).boxed()
             .toList();

List<Integer> list2 =
    IntStream.iterate(0, i -> i + 1)
             .limit(10).boxed()
             .toList();
```

`list1`和`list2`两个列表都是相同的，但是使用不同的模式创建的。第一个易于分割，而第二个不是。主要原因是，在第二个模式中，知道第五个元素的值需要计算所有前面的元素。从这个意义上说，这第二个模式看起来像一个链表，您需要访问前四个元素才能到达第五个。

## 分割和分发工作

一旦您的数据源被分割，那么两个子流就必须在CPU的不同核心上处理，以便并行化有效。

这是由Fork/Join框架完成的。Fork/Join框架处理一个线程池，当您的应用程序启动时创建，称为Common Fork/Join Pool。这个池中的线程数量与您的CPU核心数量一致。这个池中的每个线程都有一个等待队列，线程可以在其中存储任务。

1. 池中的第一个线程创建第一个任务。执行此任务决定计算是否足够小，可以顺序执行，或者太大应该被分割。
2. 如果它被分割，那么会创建两个子任务并存储在该线程的队列中。主任务然后等待两个子任务完成。在等待时，它也被存储在这个等待队列中。
3. 如果进行计算，那么会产生一个结果。这个结果是对整个计算的部分结果。然后，此任务将结果返回给创建它的主任务。
4. 一旦任务获得了它创建的两个子任务的两个结果，它就可以将它们合并以产生结果，并将其返回给创建它的主任务。

在某个时刻，第一个主任务从它的两个子任务中获得两个部分结果。然后它可以合并它们并返回计算的最终结果。

目前，唯一正在工作的线程是池中的第一个线程，它是由Fork/Join框架调用的。Fork/Join框架实现了另一种并发编程模式，称为_work stealing_。池中的一个空闲线程可以检查同一池中其他线程的等待队列，拿走一个任务并处理它。

这就是这种情况下发生的事情。只要第一个等待队列中的任务数量增加，其他线程就会开始窃取它们，处理它们，进一步分割工作，并用自己的等待队列填充更多任务。这个特性使池中的所有线程都保持忙碌。

这个工作窃取特性运作良好，但它有一个缺点：根据您的数据如何被分割以及任务如何从一个线程移动到另一个线程，您的数据可能会以任何顺序被处理。在某些情况下，这可能是一个问题。

## 处理子流

处理子流可能与处理完整流不同。两个元素可以使子流的处理与完整流不同：访问外部状态，以及将状态从一个元素的处理传递到另一个元素。这两个元素将影响您的并行流的性能。

### 访问外部状态

Fork/Join框架将您的计算分解为许多子任务，每个子任务由池中的一个线程处理。

如果您顺序处理您的流，所有元素都在运行您的方法的线程中处理。如果您并行处理相同的流，元素将由Common Fork/Join池中的线程处理。

然后从另一个线程访问流之外的状态，可能会导致竞态条件。

让我们在一个经典的`main`方法中运行以下代码。

```java
Set<String> threadNames =
    IntStream.range(0, 100)
             // .parallel()
             .mapToObj(index -> Thread.currentThread().getName())
             .collect(Collectors.toSet());

System.out.println("Thread names:");
threadNames.forEach(System.out::println);
```

它产生的结果是以下内容。

```
Thread names:
main
```

如果您取消注释`parallel()`调用，那么这个流将并行执行。结果变成以下内容，并且在您的机器上可能会有所不同。

```
Thread names:
ForkJoinPool.commonPool-worker-3
ForkJoinPool.commonPool-worker-4
ForkJoinPool.commonPool-worker-2
ForkJoinPool.commonPool-worker-4
main
ForkJoinPool.commonPool-worker-5
```

任何对非并发的外部元素的访问都可能导致竞态条件和数据不一致性。让我们运行以下代码。

```java
List<Integer> ints = new ArrayList<>();

IntStream.range(0, 1_000_000)
         .parallel()
         .forEach(ints::add);

System.out.println("ints.size() = " + ints.size());
```

多次运行此代码可能会导致不同的结果，因为Common Fork/Join Pool中的所有线程都试图在`ArrayList`的实例中并发添加数据，这不是线程安全的。看到正确结果的可能性很小，您甚至可能会得到一个`ArrayIndexOutOfBoundsException`。使用任何非并发集合或映射运行这种类型的代码会导致不可预测的结果，包括异常。

对于流来说，改变流之外的状态是一种反模式。

### 遇到顺序

在Stream API中，数据的处理顺序在某些情况下是重要的。对于以下方法就是这种情况。

- `limit(n)`：将处理限制在这组流的前`n`个元素。
- `skip(n)`：跳过这组流的前`n`个元素的处理。
- `findFirst()`：找到流的第`一个`元素。

这三种方法需要记住流的元素是如何顺序处理的，并需要计数元素以产生正确的结果。

它们被称为有状态操作，因为它们需要携带内部状态才能工作。

有这种有状态的操作会导致并行流的开销。例如，`limit()`需要一个内部计数器才能正确工作。在并行中，这个内部计数器在不同的线程之间共享。在线程之间共享可变状态是昂贵的，应该避免。

## 理解并行计算流的开销

并行计算流增加了一些计算以处理并行性。这些元素有成本，您需要知道它们，以确保这种成本不会与并行的好处相比过高。

- 您的数据需要被分割。分割可能便宜，也可能昂贵，这取决于您处理的数据。数据的局部性不好会使分割变得昂贵。
- 分割需要有效。它需要创建均匀分割的子流。有些来源可以容易地均匀分割，有些则不能。
- 一旦分割，实现就会并发处理您的数据。您应该避免访问任何外部可变状态，也要避免拥有内部共享的可变状态。
- 然后部分结果必须被合并。有些结果可以容易地合并。合并整数的和是容易且便宜的。合并集合也很容易。合并哈希映射更昂贵。

## 正确使用并行流的一些规则

**规则#1** 不要因为有趣而优化；优化是因为您有需求并且没有达到它们。

**规则#2** 小心选择您的数据源。

**规则#3** 不要修改外部状态，不要共享可变状态。

**规则#4** 不要猜测；测量您的代码性能。


